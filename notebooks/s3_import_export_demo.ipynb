{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neptune Analytics S3 Import/Export Demo\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Import data from an S3 bucket into a Neptune Analytics graph\n",
    "2. Export graph data to an S3 bucket\n",
    "\n",
    "The notebook uses boto3 to interact with the Neptune Analytics API and includes functions to wait for operations to complete before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import the necessary libraries and set up logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import boto3\n",
    "import networkx as nx\n",
    "from nx_neptune import NeptuneGraph, import_csv_from_s3, export_csv_to_s3\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "        level=logging.WARNING,\n",
    "        format='%(levelname)s - %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        stream=sys.stdout  # Explicitly set output to stdout\n",
    "    )\n",
    "for logger_name in ['IAMClient', 'nx_neptune.clients.instance_management']:\n",
    "    logging.getLogger(logger_name).setLevel(logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up the necessary environment variables for S3 bucket location and IAM role ARN. You can either set these as environment variables before starting the notebook or define them directly here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_env_vars(var_names):\n",
    "    values = {}\n",
    "    for var_name in var_names:\n",
    "        value = os.getenv(var_name)\n",
    "        if not value:\n",
    "            print(f\"Warning: Environment Variable {var_name} is not defined\")\n",
    "            print(f\"You can set it using: %env {var_name}=your-value\")\n",
    "        else:\n",
    "            print(f\"Using {var_name}: {value}\")\n",
    "        values[var_name] = value\n",
    "    return values\n",
    "    \n",
    "env_vars = check_env_vars([\n",
    "    'NETWORKX_S3_IMPORT_BUCKET_PATH',\n",
    "    'NETWORKX_S3_EXPORT_BUCKET_PATH',\n",
    "    'NETWORKX_ARN_IAM_ROLE',\n",
    "    'NETWORKX_GRAPH_ID'\n",
    "])\n",
    "\n",
    "# Get environment variables or set them directly\n",
    "# s3://BUCKET_NAME/FOLDER_NAME\n",
    "s3_location_import = os.getenv('NETWORKX_S3_IMPORT_BUCKET_PATH')\n",
    "s3_location_export = os.getenv('NETWORKX_S3_EXPORT_BUCKET_PATH')\n",
    "# arn:aws:iam::AWS_ACCOUNT:role/IAM_ROLE_NAME\n",
    "role_arn = os.getenv('NETWORKX_ARN_IAM_ROLE')\n",
    "# You can also set the Neptune Analytics Graph ID if needed\n",
    "graph_id = os.getenv('NETWORKX_GRAPH_ID')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Neptune Graph\n",
    "\n",
    "Create a NetworkX graph and initialize the Neptune Analytics graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a directed graph\n",
    "g = nx.DiGraph()\n",
    "\n",
    "# Create a Neptune Analytics graph instance\n",
    "na_graph = NeptuneGraph.from_config(graph=g)\n",
    "BACKEND = \"neptune\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data from S3 (Blocking)\n",
    "\n",
    "Import data from S3 into the Neptune Analytics graph and wait for the operation to complete. <br>\n",
    "IAM permisisons required for import: <br>\n",
    " - s3:GetObject, kms:Decrypt, kms:GenerateDataKey, kms:DescribeKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = import_csv_from_s3(\n",
    "        na_graph, s3_location_import)\n",
    "import_blocking_status = await future\n",
    "print(\"Import completed with status: \" + import_blocking_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data from S3 (Non-blocking)\n",
    "\n",
    "Import data from S3 into the Neptune Analytics graph while performing other operations.\n",
    "In this scenario, the user has the freedom to carry out other Python workloads and executions, check the job status periodically, and then proceed further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = import_csv_from_s3(\n",
    "        na_graph, s3_location_import)\n",
    "# Carry on with some other Non NA workload on python\n",
    "# .....\n",
    "\n",
    "# Periodic check on the  job status\n",
    "while not future.done():\n",
    "    print(\"Simulate analytics workload on local\")\n",
    "    await asyncio.sleep(60)\n",
    "print(\"Import completed in async fashion.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BFS Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BFS on Air route\n",
    "r = list(nx.bfs_edges(g, source=\"48\", backend=BACKEND))\n",
    "print('BFS search on NePtune Analytics with source=48 (Vanouver international airport): ')\n",
    "print(f\"Total size of the result: {len(r)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Data to S3 (Blocking)\n",
    "\n",
    "Export data from the Neptune Analytics graph to S3 and wait for the operation to complete. <br>\n",
    "After the job is completed, an additional folder—named using the job ID—will be added to the S3 path specified by the user, containing the exported files and data.\n",
    "\n",
    "IAM permisisons required for export: <br>\n",
    " - s3:GetObject, kms:Decrypt, kms:GenerateDataKey, kms:DescribeKey\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = export_csv_to_s3(\n",
    "        na_graph, s3_location_export)\n",
    "await future\n",
    "print(\"Export completed with export location: \" + s3_location_export)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Data to S3 (Non-blocking)\n",
    "\n",
    "Export data from the Neptune Analytics graph to S3 while performing other operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = export_csv_to_s3(\n",
    "        na_graph, s3_location_export)\n",
    "while not future.done():\n",
    "    print(\"Simulate analytics workload on local\")\n",
    "    await asyncio.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated how to import data from S3 into a Neptune Analytics graph and export data from the graph to S3. Both blocking and non-blocking approaches were shown, allowing you to choose the most appropriate method for your workflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
