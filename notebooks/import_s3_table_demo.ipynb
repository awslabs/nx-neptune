{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neptune Analytics Instance Management With S3 Tables Projections\n",
    "\n",
    "This notebook uses the SessionManager to create projections from S3 Table datalake, load the projection into Neptune Analytics through S3. We will use the Louvain algorithm to find potential fraudulent nodes, and export the mutated graph back into S3 for our datalake.\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Create a projection from S3 bucket.\n",
    "2. Import the projection into Neptune Analytics.\n",
    "3. Run Louvain algorithm on the provisioned instance.\n",
    "4. Export the graph back into S3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import the necessary libraries and set up logging."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T18:17:51.553149Z",
     "start_time": "2025-11-17T18:17:49.084830Z"
    }
   },
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "from nx_neptune.session_manager import SessionManager"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T18:18:29.871055Z",
     "start_time": "2025-11-17T18:18:29.868720Z"
    }
   },
   "source": [
    "# Configure logging to see detailed information about the instance creation process\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    stream=sys.stdout  # Explicitly set output to stdout\n",
    ")\n",
    "# Enable debug logging for the instance management module\n",
    "for logger_name in ['nx_neptune.instance_management', 'nx_neptune.session_manager']:\n",
    "    logging.getLogger(logger_name).setLevel(logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Check for environment variables and configure the NetworkX backend for Neptune Analytics."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T18:19:12.045296Z",
     "start_time": "2025-11-17T18:19:12.042068Z"
    }
   },
   "source": [
    "def check_env_vars(var_names):\n",
    "    values = {}\n",
    "    for var_name in var_names:\n",
    "        value = os.getenv(var_name)\n",
    "        if not value:\n",
    "            print(f\"Warning: Environment Variable {var_name} is not defined\")\n",
    "            print(f\"You can set it using: %env {var_name}=your-value\")\n",
    "        else:\n",
    "            print(f\"Using {var_name}: {value}\")\n",
    "        values[var_name] = value\n",
    "    return values\n",
    "    \n",
    "# Check for optional environment variables\n",
    "env_vars = check_env_vars([\n",
    "    'NETWORKX_S3_IMPORT_BUCKET_PATH',\n",
    "    'NETWORKX_S3_EXPORT_BUCKET_PATH',\n",
    "])\n",
    "\n",
    "# Get environment variables\n",
    "s3_location_import = os.getenv('NETWORKX_S3_IMPORT_BUCKET_PATH')  # Optional: for importing data after creation\n",
    "s3_location_export = os.getenv('NETWORKX_S3_EXPORT_BUCKET_PATH')  # Optional: for importing data after creation"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NETWORKX_S3_IMPORT_BUCKET_PATH: s3://nx-fraud-detection/projection/\n",
      "Using NETWORKX_S3_EXPORT_BUCKET_PATH: s3://nx-fraud-detection\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a New Neptune Analytics Instance\n",
    "\n",
    "Provision a new Neptune Analytics instance on demand. This process may take several minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T18:19:22.543694Z",
     "start_time": "2025-11-17T18:19:21.859032Z"
    }
   },
   "source": [
    "session = SessionManager.Session(\"example_fraud_detection\")\n",
    "graph_list = session.list_graphs()\n",
    "logger.info(f\"The following graphs are available: {graph_list}\")\n",
    "\n",
    "graph = await session.get_or_create_graph()\n",
    "logger.info(f\"Created graph: {graph}\")\n",
    "\n",
    "graph_list = session.list_graphs()\n",
    "logger.info(f\"The following graphs are available: {graph_list}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Found credentials in environment variables.\n",
      "INFO - The following graphs are available: []\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data from S3\n",
    "\n",
    "Import data from S3 into the Neptune Analytics graph and wait for the operation to complete. <br>\n",
    "IAM permisisons required for import: <br>\n",
    " - s3:GetObject, kms:Decrypt, kms:GenerateDataKey, kms:DescribeKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['NETWORKX_GRAPH_ID'] = graph_id\n",
    "na_graph = NeptuneGraph.from_config(graph=nx.DiGraph())\n",
    "future = import_csv_from_s3(\n",
    "na_graph, s3_location_import)\n",
    "import_blocking_status = await future\n",
    "print(\"Import completed with status: \" + import_blocking_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execcute BFS Algorithm\n",
    "\n",
    "Create a NetworkX graph and initialize the connection to the Neptune Analytics instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.DiGraph()\n",
    "# BFS on Air route\n",
    "r = list(nx.bfs_edges(g, source=\"48\", backend=\"neptune\"))\n",
    "print('BFS search on Neptune Analytics with source=48 (Vancouver international airport): ')\n",
    "print(f\"Total size of the result: {len(r)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the Neptune Analytics Instance\n",
    "\n",
    "Delete the Neptune Analytics instance after the computation. This process may take several minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fut = await delete_na_instance(graph_id)\n",
    "logger.info(f\"Instance delete completed with status: {fut}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated the complete lifecycle of a Neptune Analytics instance:\n",
    "\n",
    "1. **Creation**: We created a new Neptune Analytics instance on demand\n",
    "2. **Import**: We imported the demo Air Route dataset from \n",
    "3. **Usage**: We ran graph algorithms (BFS) on the instance\n",
    "4. **Deletion**: We deleted the on demand instance after the computation is conducted\n",
    "\n",
    "The `create_na_instance()` and `delete_na_instance` functions make it easy to provision and destroy Neptune Analytics resources when needed, enabling seamless scaling of graph computations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
